#***********************************************************************#
# Note: The Video class is a "facade" in the context of design pattern. 
# This class deal with all things about reading video. The outputs will
# be used by the classification class.
# This class is organized following the concept of "decorator".
#***********************************************************************#

import cv2
import imutils
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import logging
import copy
import pickle
import os
import sys
   


class Video:
    def __init__(self, cfg):
        self.cfg = cfg 
        self.fc7_csvs = []
        self.res_csvs = []
        self.tsels= []
        self.thists= []
        self.thtmls= []
        self.pic_htmls = []
        self.t1s = [] # time boundaries of video segments 
        self.t2s = []
        self.it1s = [] # index of time boundaries of video segments 
        self.it2s = []
        self.n_segs = 0
        
        try:
            self.photo_dir = cfg.photo_dir
        except:
            self.photo_dir = '%s/film_%03d' %\
                             (os.getcwd(),int(cfg.film_num))
        try:
            self.photo_csv = cfg.photo_csv
        except:
            self.photo_csv = '%s/film_%03d_photo.csv' %\
                             (cfg.csv_dir, int(cfg.film_num) )
        
            
    # A Video object containing timing information is required for running
    # clustering and time analysis. Such information is generated by split_film
    # In case split_film is omitted in the process, we create a Video object
    # by taking the whole film as a segment. 
    def init(self):
        # Copy the whole film as a film segment in case we
        # don't run split_film
        cfg = self.cfg
        df = pd.read_csv(self.photo_csv, index_col=0)
        self.fc7_csvs = ['%s/fc7_%03d_part_0.csv' %\
                           (cfg.csv_dir, int(cfg.film_num) )]
        df.to_csv(self.fc7_csvs[0])
        self.it1s, self.t1s = [0], [df.loc[0,'time']]
        self.it2s, self.t2s = [len(df)], df.loc[len(df)-1,'time']
        
        self.save()


        
   



    # Called by read_video
    def _read_video(self):
        cfg = self.cfg
        cascadePath = cfg.cascadePath  
        SAVE = True if cfg.saveFaces in['True','true'] else False
        dt = float(cfg.dt)
        videoName = cfg.videoName
        minsize = int(cfg.minsize)
        maxsize = int(cfg.maxsize)

        # Initialize haarcascade
        cascade = cv2.CascadeClassifier()
        cascade.load(cascadePath)

        # Initilize reading time
        sec = dt

        # Set up video captcher
        capture = cv2.VideoCapture(videoName)

        # Count detected faces
        i = 0

        # record filename and time
        ts = []
        filenames = []

        # Read video and detect faces
        while(1):
            logging.debug( 'reading %dth sec' % sec ) 
            capture.set(cv2.CAP_PROP_POS_MSEC, sec*1000)
            (grabbed, frame) = capture.read()
            if not grabbed:
                break
            frame = imutils.resize(frame, width=250)
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = cascade.detectMultiScale(gray, scaleFactor=1.01,
                minNeighbors=6,minSize=(minsize, minsize), maxSize=(maxsize,maxsize))
            for (x, y, w, h) in faces:
                y1 = int(y-0.5*h); y2 = int(y+1.1*h); x1 = int(x-0.3*w); x2 = int(x+1.3*w)
                logging.debug( ' %dth faces w:%d h:%d roi %d %d %d %d' % (i,w,h,x1,x2,y1,y2) )
                if x1<0  or x2<0 or y1 <0 or y2<0: continue 
                roi = frame[y1:y2,x1:x2]
                fname =  '%s/%d.png' % (self.photo_dir,i)
                if SAVE:
                    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)
                    fig = plt.figure(figsize=(3,3),dpi=80)
                    ax = fig.add_subplot(111)
                    ax.axis('off')
                    ax.imshow(roi)

                    # These ridiculously verbose lines garantee no white margins
                    # around the saved photos
                    plt.gca().set_axis_off()
                    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, 
                                        hspace = 0, wspace = 0)
                    plt.margins(0,0)
                    plt.gca().xaxis.set_major_locator(plt.NullLocator())
                    plt.gca().yaxis.set_major_locator(plt.NullLocator())
                    plt.savefig(fname,bbox_inches='tight',pad_inches = 0)
                    plt.close(fig)


                ts.append(sec)
                filenames.append(fname)
                i=i+1
            sec = sec + dt
        df = pd.DataFrame({'filename':filenames, 'time': ts})
        df['number'] = df.index
        df = df[['number','time','filename']]
        return df




    # This function deals with R/W of read_video
    # The _read_video function is called to detect faces and save them as .png
    def read_video(self):
        cfg = self.cfg
        
        if not os.path.exists(self.photo_dir):
            os.makedirs(self.photo_dir)

        # read video
        df = self._read_video()
        df.to_csv(self.photo_csv); print 'Create %s' % self.photo_csv


        # Called by split_film
    def _split_film(self, df, gap_length):
        
        gap_length = int(gap_length)
        
        # Find boundaries (index) of time gaps
        df_bds =df.loc[df.time.diff()>gap_length] # this time - previous > gap
        bd1s = [df_bds.index[i] for i in range(len(df_bds))]
        bd2s = copy.deepcopy(bd1s)

        # If bd2s is empty, add the end of the film to the boundary list
        if not len(bd2s):
            bd2s.append(len(df)-1)

        # If the last boundary is not the end of the film
        # add the film end to the boundary list
        if bd2s[-1]!= len(df)-1:
            bd2s.append(len(df)-1)

        # Add 0 to the begining
        bd1s = [0] + bd1s

        # Find the times 
        bd1_times, bd2_times = df.ix[bd1s,'time'].tolist(), df.ix[bd2s,'time'].tolist()

        return bd1s, bd1_times, bd2s, bd2_times


        
    # This function deals with R/W of split_film
    # The _split_film function is called to read the time of photos and
    # split the film according to gap_length in the configuration file
    def split_film(self):
        cfg = self.cfg
        
        # Split film
        df = pd.read_csv(self.photo_csv, index_col=0)
        self.it1s, self.t1s, self.it2s, self.t2s = self._split_film(df,cfg.gap_length)

        # Register infos
        self.n_segs = len(self.it1s)

        for i in range(self.n_segs):
            # append segment csv file name 
            i_csv1 = '%s/fc7_%03d_part_%d.csv' % (cfg.csv_dir, cfg.film_num, i)
            i_csv2 = '%s/res_%03d_part_%d.csv' % (cfg.csv_dir, cfg.film_num, i)
            i_csv3 = '%s/tsel_%03d_part_%d.csv' % (cfg.csv_dir, cfg.film_num, i)
            i_csv4 = '%s/thist_%03d_part_%d.csv' % (cfg.csv_dir, cfg.film_num, i)
            i_time = '%s/time_%03d_part_%d.html' % (cfg.html_dir, cfg.film_num, i)
            i_photos = '%s/photos_%03d_part_%d.html' % (cfg.html_dir, cfg.film_num, i)
            self.fc7_csvs.append(i_csv1)
            self.res_csvs.append(i_csv2)
            self.tsels.append(i_csv3)
            self.thists.append(i_csv4)
            self.thtmls.append(i_time)
            self.pic_htmls.append(i_photos)
            it1,it2 = self.it1s[i], self.it2s[i]
            # split fc7 file save toi_csv
            df_i = df.iloc[it1:it2]
            df_i = df_i.query('face==1').copy(deep=True)
            df_i = df_i.reset_index(drop=True)
            df_i.to_csv(i_csv1)
            
        self.save()
            
    # Save Video object for later use
    def save(self):
        with open('video_%03d.pkl' % self.cfg.film_num, 'w') as pklfile:
            pickle.dump(self,pklfile)
            
